{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6eaca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnapolitano/miniconda3/envs/vqa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "# set CUDA_VISIBLE_DEVICES=1\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, Qwen2VLForConditionalGeneration, HfArgumentParser, Qwen2_5_VLForConditionalGeneration\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591879a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/data1/dnapolitano/MM/VQAv2/validation.json\"\n",
    "image_path=\"/data2/dnapolitano/MM/data/VQA/Images/mscoco/val2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59343f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88319"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de7fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoProcessor, AutoConfig, Qwen2_5_VLForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a39d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/data2/dnapolitano/MM/scripts/Qwen2-VL-Finetune/output/lora_vision_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c42a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base=\"Qwen/Qwen2.5-VL-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e0576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_cfg_pretrained = AutoConfig.from_pretrained(model_path)\n",
    "if hasattr(lora_cfg_pretrained, 'quantization_config'):\n",
    "    del lora_cfg_pretrained.quantization_config\n",
    "# processor = AutoProcessor.from_pretrained(model_base)\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_base, min_pixels=min_pixels, max_pixels=max_pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6af00f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"device_map\": \"auto\"}\n",
    "kwargs['torch_dtype'] = torch.float16\n",
    "kwargs['attn_implementation'] = 'flash_attention_2'\n",
    "kwargs['cache_dir'] = \"/data1/hf_cache/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "075eb52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen2.5-VL from base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Loading Qwen2.5-VL from base model...')\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_base, low_cpu_mem_usage=True, config=lora_cfg_pretrained, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b469af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_num, tokem_dim = model.lm_head.out_features, model.lm_head.in_features\n",
    "if model.lm_head.weight.shape[0] != token_num:\n",
    "    model.lm_head.weight = torch.nn.Parameter(torch.empty(token_num, tokem_dim, device=model.device, dtype=model.dtype))\n",
    "    model.model.embed_tokens.weight = torch.nn.Parameter(torch.empty(token_num, tokem_dim, device=model.device, dtype=model.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7fa746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading additional Qwen2-VL weights...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['visual.blocks.0.attn.qkv.weight', 'visual.blocks.0.attn.qkv.bias', 'visual.blocks.0.attn.proj.weight', 'visual.blocks.0.attn.proj.bias', 'visual.blocks.0.mlp.gate_proj.weight', 'visual.blocks.0.mlp.gate_proj.bias', 'visual.blocks.0.mlp.up_proj.weight', 'visual.blocks.0.mlp.up_proj.bias', 'visual.blocks.0.mlp.down_proj.weight', 'visual.blocks.0.mlp.down_proj.bias', 'visual.blocks.1.attn.qkv.weight', 'visual.blocks.1.attn.qkv.bias', 'visual.blocks.1.attn.proj.weight', 'visual.blocks.1.attn.proj.bias', 'visual.blocks.1.mlp.gate_proj.weight', 'visual.blocks.1.mlp.gate_proj.bias', 'visual.blocks.1.mlp.up_proj.weight', 'visual.blocks.1.mlp.up_proj.bias', 'visual.blocks.1.mlp.down_proj.weight', 'visual.blocks.1.mlp.down_proj.bias', 'visual.blocks.2.attn.qkv.weight', 'visual.blocks.2.attn.qkv.bias', 'visual.blocks.2.attn.proj.weight', 'visual.blocks.2.attn.proj.bias', 'visual.blocks.2.mlp.gate_proj.weight', 'visual.blocks.2.mlp.gate_proj.bias', 'visual.blocks.2.mlp.up_proj.weight', 'visual.blocks.2.mlp.up_proj.bias', 'visual.blocks.2.mlp.down_proj.weight', 'visual.blocks.2.mlp.down_proj.bias', 'visual.blocks.3.attn.qkv.weight', 'visual.blocks.3.attn.qkv.bias', 'visual.blocks.3.attn.proj.weight', 'visual.blocks.3.attn.proj.bias', 'visual.blocks.3.mlp.gate_proj.weight', 'visual.blocks.3.mlp.gate_proj.bias', 'visual.blocks.3.mlp.up_proj.weight', 'visual.blocks.3.mlp.up_proj.bias', 'visual.blocks.3.mlp.down_proj.weight', 'visual.blocks.3.mlp.down_proj.bias', 'visual.blocks.4.attn.qkv.weight', 'visual.blocks.4.attn.qkv.bias', 'visual.blocks.4.attn.proj.weight', 'visual.blocks.4.attn.proj.bias', 'visual.blocks.4.mlp.gate_proj.weight', 'visual.blocks.4.mlp.gate_proj.bias', 'visual.blocks.4.mlp.up_proj.weight', 'visual.blocks.4.mlp.up_proj.bias', 'visual.blocks.4.mlp.down_proj.weight', 'visual.blocks.4.mlp.down_proj.bias', 'visual.blocks.5.attn.qkv.weight', 'visual.blocks.5.attn.qkv.bias', 'visual.blocks.5.attn.proj.weight', 'visual.blocks.5.attn.proj.bias', 'visual.blocks.5.mlp.gate_proj.weight', 'visual.blocks.5.mlp.gate_proj.bias', 'visual.blocks.5.mlp.up_proj.weight', 'visual.blocks.5.mlp.up_proj.bias', 'visual.blocks.5.mlp.down_proj.weight', 'visual.blocks.5.mlp.down_proj.bias', 'visual.blocks.6.attn.qkv.weight', 'visual.blocks.6.attn.qkv.bias', 'visual.blocks.6.attn.proj.weight', 'visual.blocks.6.attn.proj.bias', 'visual.blocks.6.mlp.gate_proj.weight', 'visual.blocks.6.mlp.gate_proj.bias', 'visual.blocks.6.mlp.up_proj.weight', 'visual.blocks.6.mlp.up_proj.bias', 'visual.blocks.6.mlp.down_proj.weight', 'visual.blocks.6.mlp.down_proj.bias', 'visual.blocks.7.attn.qkv.weight', 'visual.blocks.7.attn.qkv.bias', 'visual.blocks.7.attn.proj.weight', 'visual.blocks.7.attn.proj.bias', 'visual.blocks.7.mlp.gate_proj.weight', 'visual.blocks.7.mlp.gate_proj.bias', 'visual.blocks.7.mlp.up_proj.weight', 'visual.blocks.7.mlp.up_proj.bias', 'visual.blocks.7.mlp.down_proj.weight', 'visual.blocks.7.mlp.down_proj.bias', 'visual.blocks.8.attn.qkv.weight', 'visual.blocks.8.attn.qkv.bias', 'visual.blocks.8.attn.proj.weight', 'visual.blocks.8.attn.proj.bias', 'visual.blocks.8.mlp.gate_proj.weight', 'visual.blocks.8.mlp.gate_proj.bias', 'visual.blocks.8.mlp.up_proj.weight', 'visual.blocks.8.mlp.up_proj.bias', 'visual.blocks.8.mlp.down_proj.weight', 'visual.blocks.8.mlp.down_proj.bias', 'visual.blocks.9.attn.qkv.weight', 'visual.blocks.9.attn.qkv.bias', 'visual.blocks.9.attn.proj.weight', 'visual.blocks.9.attn.proj.bias', 'visual.blocks.9.mlp.gate_proj.weight', 'visual.blocks.9.mlp.gate_proj.bias', 'visual.blocks.9.mlp.up_proj.weight', 'visual.blocks.9.mlp.up_proj.bias', 'visual.blocks.9.mlp.down_proj.weight', 'visual.blocks.9.mlp.down_proj.bias', 'visual.blocks.10.attn.qkv.weight', 'visual.blocks.10.attn.qkv.bias', 'visual.blocks.10.attn.proj.weight', 'visual.blocks.10.attn.proj.bias', 'visual.blocks.10.mlp.gate_proj.weight', 'visual.blocks.10.mlp.gate_proj.bias', 'visual.blocks.10.mlp.up_proj.weight', 'visual.blocks.10.mlp.up_proj.bias', 'visual.blocks.10.mlp.down_proj.weight', 'visual.blocks.10.mlp.down_proj.bias', 'visual.blocks.11.attn.qkv.weight', 'visual.blocks.11.attn.qkv.bias', 'visual.blocks.11.attn.proj.weight', 'visual.blocks.11.attn.proj.bias', 'visual.blocks.11.mlp.gate_proj.weight', 'visual.blocks.11.mlp.gate_proj.bias', 'visual.blocks.11.mlp.up_proj.weight', 'visual.blocks.11.mlp.up_proj.bias', 'visual.blocks.11.mlp.down_proj.weight', 'visual.blocks.11.mlp.down_proj.bias', 'visual.blocks.12.attn.qkv.weight', 'visual.blocks.12.attn.qkv.bias', 'visual.blocks.12.attn.proj.weight', 'visual.blocks.12.attn.proj.bias', 'visual.blocks.12.mlp.gate_proj.weight', 'visual.blocks.12.mlp.gate_proj.bias', 'visual.blocks.12.mlp.up_proj.weight', 'visual.blocks.12.mlp.up_proj.bias', 'visual.blocks.12.mlp.down_proj.weight', 'visual.blocks.12.mlp.down_proj.bias', 'visual.blocks.13.attn.qkv.weight', 'visual.blocks.13.attn.qkv.bias', 'visual.blocks.13.attn.proj.weight', 'visual.blocks.13.attn.proj.bias', 'visual.blocks.13.mlp.gate_proj.weight', 'visual.blocks.13.mlp.gate_proj.bias', 'visual.blocks.13.mlp.up_proj.weight', 'visual.blocks.13.mlp.up_proj.bias', 'visual.blocks.13.mlp.down_proj.weight', 'visual.blocks.13.mlp.down_proj.bias', 'visual.blocks.14.attn.qkv.weight', 'visual.blocks.14.attn.qkv.bias', 'visual.blocks.14.attn.proj.weight', 'visual.blocks.14.attn.proj.bias', 'visual.blocks.14.mlp.gate_proj.weight', 'visual.blocks.14.mlp.gate_proj.bias', 'visual.blocks.14.mlp.up_proj.weight', 'visual.blocks.14.mlp.up_proj.bias', 'visual.blocks.14.mlp.down_proj.weight', 'visual.blocks.14.mlp.down_proj.bias', 'visual.blocks.15.attn.qkv.weight', 'visual.blocks.15.attn.qkv.bias', 'visual.blocks.15.attn.proj.weight', 'visual.blocks.15.attn.proj.bias', 'visual.blocks.15.mlp.gate_proj.weight', 'visual.blocks.15.mlp.gate_proj.bias', 'visual.blocks.15.mlp.up_proj.weight', 'visual.blocks.15.mlp.up_proj.bias', 'visual.blocks.15.mlp.down_proj.weight', 'visual.blocks.15.mlp.down_proj.bias', 'visual.blocks.16.attn.qkv.weight', 'visual.blocks.16.attn.qkv.bias', 'visual.blocks.16.attn.proj.weight', 'visual.blocks.16.attn.proj.bias', 'visual.blocks.16.mlp.gate_proj.weight', 'visual.blocks.16.mlp.gate_proj.bias', 'visual.blocks.16.mlp.up_proj.weight', 'visual.blocks.16.mlp.up_proj.bias', 'visual.blocks.16.mlp.down_proj.weight', 'visual.blocks.16.mlp.down_proj.bias', 'visual.blocks.17.attn.qkv.weight', 'visual.blocks.17.attn.qkv.bias', 'visual.blocks.17.attn.proj.weight', 'visual.blocks.17.attn.proj.bias', 'visual.blocks.17.mlp.gate_proj.weight', 'visual.blocks.17.mlp.gate_proj.bias', 'visual.blocks.17.mlp.up_proj.weight', 'visual.blocks.17.mlp.up_proj.bias', 'visual.blocks.17.mlp.down_proj.weight', 'visual.blocks.17.mlp.down_proj.bias', 'visual.blocks.18.attn.qkv.weight', 'visual.blocks.18.attn.qkv.bias', 'visual.blocks.18.attn.proj.weight', 'visual.blocks.18.attn.proj.bias', 'visual.blocks.18.mlp.gate_proj.weight', 'visual.blocks.18.mlp.gate_proj.bias', 'visual.blocks.18.mlp.up_proj.weight', 'visual.blocks.18.mlp.up_proj.bias', 'visual.blocks.18.mlp.down_proj.weight', 'visual.blocks.18.mlp.down_proj.bias', 'visual.blocks.19.attn.qkv.weight', 'visual.blocks.19.attn.qkv.bias', 'visual.blocks.19.attn.proj.weight', 'visual.blocks.19.attn.proj.bias', 'visual.blocks.19.mlp.gate_proj.weight', 'visual.blocks.19.mlp.gate_proj.bias', 'visual.blocks.19.mlp.up_proj.weight', 'visual.blocks.19.mlp.up_proj.bias', 'visual.blocks.19.mlp.down_proj.weight', 'visual.blocks.19.mlp.down_proj.bias', 'visual.blocks.20.attn.qkv.weight', 'visual.blocks.20.attn.qkv.bias', 'visual.blocks.20.attn.proj.weight', 'visual.blocks.20.attn.proj.bias', 'visual.blocks.20.mlp.gate_proj.weight', 'visual.blocks.20.mlp.gate_proj.bias', 'visual.blocks.20.mlp.up_proj.weight', 'visual.blocks.20.mlp.up_proj.bias', 'visual.blocks.20.mlp.down_proj.weight', 'visual.blocks.20.mlp.down_proj.bias', 'visual.blocks.21.attn.qkv.weight', 'visual.blocks.21.attn.qkv.bias', 'visual.blocks.21.attn.proj.weight', 'visual.blocks.21.attn.proj.bias', 'visual.blocks.21.mlp.gate_proj.weight', 'visual.blocks.21.mlp.gate_proj.bias', 'visual.blocks.21.mlp.up_proj.weight', 'visual.blocks.21.mlp.up_proj.bias', 'visual.blocks.21.mlp.down_proj.weight', 'visual.blocks.21.mlp.down_proj.bias', 'visual.blocks.22.attn.qkv.weight', 'visual.blocks.22.attn.qkv.bias', 'visual.blocks.22.attn.proj.weight', 'visual.blocks.22.attn.proj.bias', 'visual.blocks.22.mlp.gate_proj.weight', 'visual.blocks.22.mlp.gate_proj.bias', 'visual.blocks.22.mlp.up_proj.weight', 'visual.blocks.22.mlp.up_proj.bias', 'visual.blocks.22.mlp.down_proj.weight', 'visual.blocks.22.mlp.down_proj.bias', 'visual.blocks.23.attn.qkv.weight', 'visual.blocks.23.attn.qkv.bias', 'visual.blocks.23.attn.proj.weight', 'visual.blocks.23.attn.proj.bias', 'visual.blocks.23.mlp.gate_proj.weight', 'visual.blocks.23.mlp.gate_proj.bias', 'visual.blocks.23.mlp.up_proj.weight', 'visual.blocks.23.mlp.up_proj.bias', 'visual.blocks.23.mlp.down_proj.weight', 'visual.blocks.23.mlp.down_proj.bias', 'visual.blocks.24.attn.qkv.weight', 'visual.blocks.24.attn.qkv.bias', 'visual.blocks.24.attn.proj.weight', 'visual.blocks.24.attn.proj.bias', 'visual.blocks.24.mlp.gate_proj.weight', 'visual.blocks.24.mlp.gate_proj.bias', 'visual.blocks.24.mlp.up_proj.weight', 'visual.blocks.24.mlp.up_proj.bias', 'visual.blocks.24.mlp.down_proj.weight', 'visual.blocks.24.mlp.down_proj.bias', 'visual.blocks.25.attn.qkv.weight', 'visual.blocks.25.attn.qkv.bias', 'visual.blocks.25.attn.proj.weight', 'visual.blocks.25.attn.proj.bias', 'visual.blocks.25.mlp.gate_proj.weight', 'visual.blocks.25.mlp.gate_proj.bias', 'visual.blocks.25.mlp.up_proj.weight', 'visual.blocks.25.mlp.up_proj.bias', 'visual.blocks.25.mlp.down_proj.weight', 'visual.blocks.25.mlp.down_proj.bias', 'visual.blocks.26.attn.qkv.weight', 'visual.blocks.26.attn.qkv.bias', 'visual.blocks.26.attn.proj.weight', 'visual.blocks.26.attn.proj.bias', 'visual.blocks.26.mlp.gate_proj.weight', 'visual.blocks.26.mlp.gate_proj.bias', 'visual.blocks.26.mlp.up_proj.weight', 'visual.blocks.26.mlp.up_proj.bias', 'visual.blocks.26.mlp.down_proj.weight', 'visual.blocks.26.mlp.down_proj.bias', 'visual.blocks.27.attn.qkv.weight', 'visual.blocks.27.attn.qkv.bias', 'visual.blocks.27.attn.proj.weight', 'visual.blocks.27.attn.proj.bias', 'visual.blocks.27.mlp.gate_proj.weight', 'visual.blocks.27.mlp.gate_proj.bias', 'visual.blocks.27.mlp.up_proj.weight', 'visual.blocks.27.mlp.up_proj.bias', 'visual.blocks.27.mlp.down_proj.weight', 'visual.blocks.27.mlp.down_proj.bias', 'visual.blocks.28.attn.qkv.weight', 'visual.blocks.28.attn.qkv.bias', 'visual.blocks.28.attn.proj.weight', 'visual.blocks.28.attn.proj.bias', 'visual.blocks.28.mlp.gate_proj.weight', 'visual.blocks.28.mlp.gate_proj.bias', 'visual.blocks.28.mlp.up_proj.weight', 'visual.blocks.28.mlp.up_proj.bias', 'visual.blocks.28.mlp.down_proj.weight', 'visual.blocks.28.mlp.down_proj.bias', 'visual.blocks.29.attn.qkv.weight', 'visual.blocks.29.attn.qkv.bias', 'visual.blocks.29.attn.proj.weight', 'visual.blocks.29.attn.proj.bias', 'visual.blocks.29.mlp.gate_proj.weight', 'visual.blocks.29.mlp.gate_proj.bias', 'visual.blocks.29.mlp.up_proj.weight', 'visual.blocks.29.mlp.up_proj.bias', 'visual.blocks.29.mlp.down_proj.weight', 'visual.blocks.29.mlp.down_proj.bias', 'visual.blocks.30.attn.qkv.weight', 'visual.blocks.30.attn.qkv.bias', 'visual.blocks.30.attn.proj.weight', 'visual.blocks.30.attn.proj.bias', 'visual.blocks.30.mlp.gate_proj.weight', 'visual.blocks.30.mlp.gate_proj.bias', 'visual.blocks.30.mlp.up_proj.weight', 'visual.blocks.30.mlp.up_proj.bias', 'visual.blocks.30.mlp.down_proj.weight', 'visual.blocks.30.mlp.down_proj.bias', 'visual.blocks.31.attn.qkv.weight', 'visual.blocks.31.attn.qkv.bias', 'visual.blocks.31.attn.proj.weight', 'visual.blocks.31.attn.proj.bias', 'visual.blocks.31.mlp.gate_proj.weight', 'visual.blocks.31.mlp.gate_proj.bias', 'visual.blocks.31.mlp.up_proj.weight', 'visual.blocks.31.mlp.up_proj.bias', 'visual.blocks.31.mlp.down_proj.weight', 'visual.blocks.31.mlp.down_proj.bias', 'visual.merger.mlp.0.weight', 'visual.merger.mlp.0.bias', 'visual.merger.mlp.2.weight', 'visual.merger.mlp.2.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.q_proj.bias', 'model.layers.32.self_attn.k_proj.weight', 'model.layers.32.self_attn.k_proj.bias', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.32.self_attn.v_proj.bias', 'model.layers.32.self_attn.o_proj.weight', 'model.layers.32.mlp.gate_proj.weight', 'model.layers.32.mlp.up_proj.weight', 'model.layers.32.mlp.down_proj.weight', 'model.layers.33.self_attn.q_proj.weight', 'model.layers.33.self_attn.q_proj.bias', 'model.layers.33.self_attn.k_proj.weight', 'model.layers.33.self_attn.k_proj.bias', 'model.layers.33.self_attn.v_proj.weight', 'model.layers.33.self_attn.v_proj.bias', 'model.layers.33.self_attn.o_proj.weight', 'model.layers.33.mlp.gate_proj.weight', 'model.layers.33.mlp.up_proj.weight', 'model.layers.33.mlp.down_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.q_proj.bias', 'model.layers.34.self_attn.k_proj.weight', 'model.layers.34.self_attn.k_proj.bias', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.34.self_attn.v_proj.bias', 'model.layers.34.self_attn.o_proj.weight', 'model.layers.34.mlp.gate_proj.weight', 'model.layers.34.mlp.up_proj.weight', 'model.layers.34.mlp.down_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.q_proj.bias', 'model.layers.35.self_attn.k_proj.weight', 'model.layers.35.self_attn.k_proj.bias', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.35.self_attn.v_proj.bias', 'model.layers.35.self_attn.o_proj.weight', 'model.layers.35.mlp.gate_proj.weight', 'model.layers.35.mlp.up_proj.weight', 'model.layers.35.mlp.down_proj.weight', 'lm_head.weight'], unexpected_keys=['visual.blocks.0.attn.qkv.base_layer.weight', 'visual.blocks.0.attn.qkv.base_layer.bias', 'visual.blocks.0.attn.proj.base_layer.weight', 'visual.blocks.0.attn.proj.base_layer.bias', 'visual.blocks.0.mlp.gate_proj.base_layer.weight', 'visual.blocks.0.mlp.gate_proj.base_layer.bias', 'visual.blocks.0.mlp.up_proj.base_layer.weight', 'visual.blocks.0.mlp.up_proj.base_layer.bias', 'visual.blocks.0.mlp.down_proj.base_layer.weight', 'visual.blocks.0.mlp.down_proj.base_layer.bias', 'visual.blocks.1.attn.qkv.base_layer.weight', 'visual.blocks.1.attn.qkv.base_layer.bias', 'visual.blocks.1.attn.proj.base_layer.weight', 'visual.blocks.1.attn.proj.base_layer.bias', 'visual.blocks.1.mlp.gate_proj.base_layer.weight', 'visual.blocks.1.mlp.gate_proj.base_layer.bias', 'visual.blocks.1.mlp.up_proj.base_layer.weight', 'visual.blocks.1.mlp.up_proj.base_layer.bias', 'visual.blocks.1.mlp.down_proj.base_layer.weight', 'visual.blocks.1.mlp.down_proj.base_layer.bias', 'visual.blocks.2.attn.qkv.base_layer.weight', 'visual.blocks.2.attn.qkv.base_layer.bias', 'visual.blocks.2.attn.proj.base_layer.weight', 'visual.blocks.2.attn.proj.base_layer.bias', 'visual.blocks.2.mlp.gate_proj.base_layer.weight', 'visual.blocks.2.mlp.gate_proj.base_layer.bias', 'visual.blocks.2.mlp.up_proj.base_layer.weight', 'visual.blocks.2.mlp.up_proj.base_layer.bias', 'visual.blocks.2.mlp.down_proj.base_layer.weight', 'visual.blocks.2.mlp.down_proj.base_layer.bias', 'visual.blocks.3.attn.qkv.base_layer.weight', 'visual.blocks.3.attn.qkv.base_layer.bias', 'visual.blocks.3.attn.proj.base_layer.weight', 'visual.blocks.3.attn.proj.base_layer.bias', 'visual.blocks.3.mlp.gate_proj.base_layer.weight', 'visual.blocks.3.mlp.gate_proj.base_layer.bias', 'visual.blocks.3.mlp.up_proj.base_layer.weight', 'visual.blocks.3.mlp.up_proj.base_layer.bias', 'visual.blocks.3.mlp.down_proj.base_layer.weight', 'visual.blocks.3.mlp.down_proj.base_layer.bias', 'visual.blocks.4.attn.qkv.base_layer.weight', 'visual.blocks.4.attn.qkv.base_layer.bias', 'visual.blocks.4.attn.proj.base_layer.weight', 'visual.blocks.4.attn.proj.base_layer.bias', 'visual.blocks.4.mlp.gate_proj.base_layer.weight', 'visual.blocks.4.mlp.gate_proj.base_layer.bias', 'visual.blocks.4.mlp.up_proj.base_layer.weight', 'visual.blocks.4.mlp.up_proj.base_layer.bias', 'visual.blocks.4.mlp.down_proj.base_layer.weight', 'visual.blocks.4.mlp.down_proj.base_layer.bias', 'visual.blocks.5.attn.qkv.base_layer.weight', 'visual.blocks.5.attn.qkv.base_layer.bias', 'visual.blocks.5.attn.proj.base_layer.weight', 'visual.blocks.5.attn.proj.base_layer.bias', 'visual.blocks.5.mlp.gate_proj.base_layer.weight', 'visual.blocks.5.mlp.gate_proj.base_layer.bias', 'visual.blocks.5.mlp.up_proj.base_layer.weight', 'visual.blocks.5.mlp.up_proj.base_layer.bias', 'visual.blocks.5.mlp.down_proj.base_layer.weight', 'visual.blocks.5.mlp.down_proj.base_layer.bias', 'visual.blocks.6.attn.qkv.base_layer.weight', 'visual.blocks.6.attn.qkv.base_layer.bias', 'visual.blocks.6.attn.proj.base_layer.weight', 'visual.blocks.6.attn.proj.base_layer.bias', 'visual.blocks.6.mlp.gate_proj.base_layer.weight', 'visual.blocks.6.mlp.gate_proj.base_layer.bias', 'visual.blocks.6.mlp.up_proj.base_layer.weight', 'visual.blocks.6.mlp.up_proj.base_layer.bias', 'visual.blocks.6.mlp.down_proj.base_layer.weight', 'visual.blocks.6.mlp.down_proj.base_layer.bias', 'visual.blocks.7.attn.qkv.base_layer.weight', 'visual.blocks.7.attn.qkv.base_layer.bias', 'visual.blocks.7.attn.proj.base_layer.weight', 'visual.blocks.7.attn.proj.base_layer.bias', 'visual.blocks.7.mlp.gate_proj.base_layer.weight', 'visual.blocks.7.mlp.gate_proj.base_layer.bias', 'visual.blocks.7.mlp.up_proj.base_layer.weight', 'visual.blocks.7.mlp.up_proj.base_layer.bias', 'visual.blocks.7.mlp.down_proj.base_layer.weight', 'visual.blocks.7.mlp.down_proj.base_layer.bias', 'visual.blocks.8.attn.qkv.base_layer.weight', 'visual.blocks.8.attn.qkv.base_layer.bias', 'visual.blocks.8.attn.proj.base_layer.weight', 'visual.blocks.8.attn.proj.base_layer.bias', 'visual.blocks.8.mlp.gate_proj.base_layer.weight', 'visual.blocks.8.mlp.gate_proj.base_layer.bias', 'visual.blocks.8.mlp.up_proj.base_layer.weight', 'visual.blocks.8.mlp.up_proj.base_layer.bias', 'visual.blocks.8.mlp.down_proj.base_layer.weight', 'visual.blocks.8.mlp.down_proj.base_layer.bias', 'visual.blocks.9.attn.qkv.base_layer.weight', 'visual.blocks.9.attn.qkv.base_layer.bias', 'visual.blocks.9.attn.proj.base_layer.weight', 'visual.blocks.9.attn.proj.base_layer.bias', 'visual.blocks.9.mlp.gate_proj.base_layer.weight', 'visual.blocks.9.mlp.gate_proj.base_layer.bias', 'visual.blocks.9.mlp.up_proj.base_layer.weight', 'visual.blocks.9.mlp.up_proj.base_layer.bias', 'visual.blocks.9.mlp.down_proj.base_layer.weight', 'visual.blocks.9.mlp.down_proj.base_layer.bias', 'visual.blocks.10.attn.qkv.base_layer.weight', 'visual.blocks.10.attn.qkv.base_layer.bias', 'visual.blocks.10.attn.proj.base_layer.weight', 'visual.blocks.10.attn.proj.base_layer.bias', 'visual.blocks.10.mlp.gate_proj.base_layer.weight', 'visual.blocks.10.mlp.gate_proj.base_layer.bias', 'visual.blocks.10.mlp.up_proj.base_layer.weight', 'visual.blocks.10.mlp.up_proj.base_layer.bias', 'visual.blocks.10.mlp.down_proj.base_layer.weight', 'visual.blocks.10.mlp.down_proj.base_layer.bias', 'visual.blocks.11.attn.qkv.base_layer.weight', 'visual.blocks.11.attn.qkv.base_layer.bias', 'visual.blocks.11.attn.proj.base_layer.weight', 'visual.blocks.11.attn.proj.base_layer.bias', 'visual.blocks.11.mlp.gate_proj.base_layer.weight', 'visual.blocks.11.mlp.gate_proj.base_layer.bias', 'visual.blocks.11.mlp.up_proj.base_layer.weight', 'visual.blocks.11.mlp.up_proj.base_layer.bias', 'visual.blocks.11.mlp.down_proj.base_layer.weight', 'visual.blocks.11.mlp.down_proj.base_layer.bias', 'visual.blocks.12.attn.qkv.base_layer.weight', 'visual.blocks.12.attn.qkv.base_layer.bias', 'visual.blocks.12.attn.proj.base_layer.weight', 'visual.blocks.12.attn.proj.base_layer.bias', 'visual.blocks.12.mlp.gate_proj.base_layer.weight', 'visual.blocks.12.mlp.gate_proj.base_layer.bias', 'visual.blocks.12.mlp.up_proj.base_layer.weight', 'visual.blocks.12.mlp.up_proj.base_layer.bias', 'visual.blocks.12.mlp.down_proj.base_layer.weight', 'visual.blocks.12.mlp.down_proj.base_layer.bias', 'visual.blocks.13.attn.qkv.base_layer.weight', 'visual.blocks.13.attn.qkv.base_layer.bias', 'visual.blocks.13.attn.proj.base_layer.weight', 'visual.blocks.13.attn.proj.base_layer.bias', 'visual.blocks.13.mlp.gate_proj.base_layer.weight', 'visual.blocks.13.mlp.gate_proj.base_layer.bias', 'visual.blocks.13.mlp.up_proj.base_layer.weight', 'visual.blocks.13.mlp.up_proj.base_layer.bias', 'visual.blocks.13.mlp.down_proj.base_layer.weight', 'visual.blocks.13.mlp.down_proj.base_layer.bias', 'visual.blocks.14.attn.qkv.base_layer.weight', 'visual.blocks.14.attn.qkv.base_layer.bias', 'visual.blocks.14.attn.proj.base_layer.weight', 'visual.blocks.14.attn.proj.base_layer.bias', 'visual.blocks.14.mlp.gate_proj.base_layer.weight', 'visual.blocks.14.mlp.gate_proj.base_layer.bias', 'visual.blocks.14.mlp.up_proj.base_layer.weight', 'visual.blocks.14.mlp.up_proj.base_layer.bias', 'visual.blocks.14.mlp.down_proj.base_layer.weight', 'visual.blocks.14.mlp.down_proj.base_layer.bias', 'visual.blocks.15.attn.qkv.base_layer.weight', 'visual.blocks.15.attn.qkv.base_layer.bias', 'visual.blocks.15.attn.proj.base_layer.weight', 'visual.blocks.15.attn.proj.base_layer.bias', 'visual.blocks.15.mlp.gate_proj.base_layer.weight', 'visual.blocks.15.mlp.gate_proj.base_layer.bias', 'visual.blocks.15.mlp.up_proj.base_layer.weight', 'visual.blocks.15.mlp.up_proj.base_layer.bias', 'visual.blocks.15.mlp.down_proj.base_layer.weight', 'visual.blocks.15.mlp.down_proj.base_layer.bias', 'visual.blocks.16.attn.qkv.base_layer.weight', 'visual.blocks.16.attn.qkv.base_layer.bias', 'visual.blocks.16.attn.proj.base_layer.weight', 'visual.blocks.16.attn.proj.base_layer.bias', 'visual.blocks.16.mlp.gate_proj.base_layer.weight', 'visual.blocks.16.mlp.gate_proj.base_layer.bias', 'visual.blocks.16.mlp.up_proj.base_layer.weight', 'visual.blocks.16.mlp.up_proj.base_layer.bias', 'visual.blocks.16.mlp.down_proj.base_layer.weight', 'visual.blocks.16.mlp.down_proj.base_layer.bias', 'visual.blocks.17.attn.qkv.base_layer.weight', 'visual.blocks.17.attn.qkv.base_layer.bias', 'visual.blocks.17.attn.proj.base_layer.weight', 'visual.blocks.17.attn.proj.base_layer.bias', 'visual.blocks.17.mlp.gate_proj.base_layer.weight', 'visual.blocks.17.mlp.gate_proj.base_layer.bias', 'visual.blocks.17.mlp.up_proj.base_layer.weight', 'visual.blocks.17.mlp.up_proj.base_layer.bias', 'visual.blocks.17.mlp.down_proj.base_layer.weight', 'visual.blocks.17.mlp.down_proj.base_layer.bias', 'visual.blocks.18.attn.qkv.base_layer.weight', 'visual.blocks.18.attn.qkv.base_layer.bias', 'visual.blocks.18.attn.proj.base_layer.weight', 'visual.blocks.18.attn.proj.base_layer.bias', 'visual.blocks.18.mlp.gate_proj.base_layer.weight', 'visual.blocks.18.mlp.gate_proj.base_layer.bias', 'visual.blocks.18.mlp.up_proj.base_layer.weight', 'visual.blocks.18.mlp.up_proj.base_layer.bias', 'visual.blocks.18.mlp.down_proj.base_layer.weight', 'visual.blocks.18.mlp.down_proj.base_layer.bias', 'visual.blocks.19.attn.qkv.base_layer.weight', 'visual.blocks.19.attn.qkv.base_layer.bias', 'visual.blocks.19.attn.proj.base_layer.weight', 'visual.blocks.19.attn.proj.base_layer.bias', 'visual.blocks.19.mlp.gate_proj.base_layer.weight', 'visual.blocks.19.mlp.gate_proj.base_layer.bias', 'visual.blocks.19.mlp.up_proj.base_layer.weight', 'visual.blocks.19.mlp.up_proj.base_layer.bias', 'visual.blocks.19.mlp.down_proj.base_layer.weight', 'visual.blocks.19.mlp.down_proj.base_layer.bias', 'visual.blocks.20.attn.qkv.base_layer.weight', 'visual.blocks.20.attn.qkv.base_layer.bias', 'visual.blocks.20.attn.proj.base_layer.weight', 'visual.blocks.20.attn.proj.base_layer.bias', 'visual.blocks.20.mlp.gate_proj.base_layer.weight', 'visual.blocks.20.mlp.gate_proj.base_layer.bias', 'visual.blocks.20.mlp.up_proj.base_layer.weight', 'visual.blocks.20.mlp.up_proj.base_layer.bias', 'visual.blocks.20.mlp.down_proj.base_layer.weight', 'visual.blocks.20.mlp.down_proj.base_layer.bias', 'visual.blocks.21.attn.qkv.base_layer.weight', 'visual.blocks.21.attn.qkv.base_layer.bias', 'visual.blocks.21.attn.proj.base_layer.weight', 'visual.blocks.21.attn.proj.base_layer.bias', 'visual.blocks.21.mlp.gate_proj.base_layer.weight', 'visual.blocks.21.mlp.gate_proj.base_layer.bias', 'visual.blocks.21.mlp.up_proj.base_layer.weight', 'visual.blocks.21.mlp.up_proj.base_layer.bias', 'visual.blocks.21.mlp.down_proj.base_layer.weight', 'visual.blocks.21.mlp.down_proj.base_layer.bias', 'visual.blocks.22.attn.qkv.base_layer.weight', 'visual.blocks.22.attn.qkv.base_layer.bias', 'visual.blocks.22.attn.proj.base_layer.weight', 'visual.blocks.22.attn.proj.base_layer.bias', 'visual.blocks.22.mlp.gate_proj.base_layer.weight', 'visual.blocks.22.mlp.gate_proj.base_layer.bias', 'visual.blocks.22.mlp.up_proj.base_layer.weight', 'visual.blocks.22.mlp.up_proj.base_layer.bias', 'visual.blocks.22.mlp.down_proj.base_layer.weight', 'visual.blocks.22.mlp.down_proj.base_layer.bias', 'visual.blocks.23.attn.qkv.base_layer.weight', 'visual.blocks.23.attn.qkv.base_layer.bias', 'visual.blocks.23.attn.proj.base_layer.weight', 'visual.blocks.23.attn.proj.base_layer.bias', 'visual.blocks.23.mlp.gate_proj.base_layer.weight', 'visual.blocks.23.mlp.gate_proj.base_layer.bias', 'visual.blocks.23.mlp.up_proj.base_layer.weight', 'visual.blocks.23.mlp.up_proj.base_layer.bias', 'visual.blocks.23.mlp.down_proj.base_layer.weight', 'visual.blocks.23.mlp.down_proj.base_layer.bias', 'visual.blocks.24.attn.qkv.base_layer.weight', 'visual.blocks.24.attn.qkv.base_layer.bias', 'visual.blocks.24.attn.proj.base_layer.weight', 'visual.blocks.24.attn.proj.base_layer.bias', 'visual.blocks.24.mlp.gate_proj.base_layer.weight', 'visual.blocks.24.mlp.gate_proj.base_layer.bias', 'visual.blocks.24.mlp.up_proj.base_layer.weight', 'visual.blocks.24.mlp.up_proj.base_layer.bias', 'visual.blocks.24.mlp.down_proj.base_layer.weight', 'visual.blocks.24.mlp.down_proj.base_layer.bias', 'visual.blocks.25.attn.qkv.base_layer.weight', 'visual.blocks.25.attn.qkv.base_layer.bias', 'visual.blocks.25.attn.proj.base_layer.weight', 'visual.blocks.25.attn.proj.base_layer.bias', 'visual.blocks.25.mlp.gate_proj.base_layer.weight', 'visual.blocks.25.mlp.gate_proj.base_layer.bias', 'visual.blocks.25.mlp.up_proj.base_layer.weight', 'visual.blocks.25.mlp.up_proj.base_layer.bias', 'visual.blocks.25.mlp.down_proj.base_layer.weight', 'visual.blocks.25.mlp.down_proj.base_layer.bias', 'visual.blocks.26.attn.qkv.base_layer.weight', 'visual.blocks.26.attn.qkv.base_layer.bias', 'visual.blocks.26.attn.proj.base_layer.weight', 'visual.blocks.26.attn.proj.base_layer.bias', 'visual.blocks.26.mlp.gate_proj.base_layer.weight', 'visual.blocks.26.mlp.gate_proj.base_layer.bias', 'visual.blocks.26.mlp.up_proj.base_layer.weight', 'visual.blocks.26.mlp.up_proj.base_layer.bias', 'visual.blocks.26.mlp.down_proj.base_layer.weight', 'visual.blocks.26.mlp.down_proj.base_layer.bias', 'visual.blocks.27.attn.qkv.base_layer.weight', 'visual.blocks.27.attn.qkv.base_layer.bias', 'visual.blocks.27.attn.proj.base_layer.weight', 'visual.blocks.27.attn.proj.base_layer.bias', 'visual.blocks.27.mlp.gate_proj.base_layer.weight', 'visual.blocks.27.mlp.gate_proj.base_layer.bias', 'visual.blocks.27.mlp.up_proj.base_layer.weight', 'visual.blocks.27.mlp.up_proj.base_layer.bias', 'visual.blocks.27.mlp.down_proj.base_layer.weight', 'visual.blocks.27.mlp.down_proj.base_layer.bias', 'visual.blocks.28.attn.qkv.base_layer.weight', 'visual.blocks.28.attn.qkv.base_layer.bias', 'visual.blocks.28.attn.proj.base_layer.weight', 'visual.blocks.28.attn.proj.base_layer.bias', 'visual.blocks.28.mlp.gate_proj.base_layer.weight', 'visual.blocks.28.mlp.gate_proj.base_layer.bias', 'visual.blocks.28.mlp.up_proj.base_layer.weight', 'visual.blocks.28.mlp.up_proj.base_layer.bias', 'visual.blocks.28.mlp.down_proj.base_layer.weight', 'visual.blocks.28.mlp.down_proj.base_layer.bias', 'visual.blocks.29.attn.qkv.base_layer.weight', 'visual.blocks.29.attn.qkv.base_layer.bias', 'visual.blocks.29.attn.proj.base_layer.weight', 'visual.blocks.29.attn.proj.base_layer.bias', 'visual.blocks.29.mlp.gate_proj.base_layer.weight', 'visual.blocks.29.mlp.gate_proj.base_layer.bias', 'visual.blocks.29.mlp.up_proj.base_layer.weight', 'visual.blocks.29.mlp.up_proj.base_layer.bias', 'visual.blocks.29.mlp.down_proj.base_layer.weight', 'visual.blocks.29.mlp.down_proj.base_layer.bias', 'visual.blocks.30.attn.qkv.base_layer.weight', 'visual.blocks.30.attn.qkv.base_layer.bias', 'visual.blocks.30.attn.proj.base_layer.weight', 'visual.blocks.30.attn.proj.base_layer.bias', 'visual.blocks.30.mlp.gate_proj.base_layer.weight', 'visual.blocks.30.mlp.gate_proj.base_layer.bias', 'visual.blocks.30.mlp.up_proj.base_layer.weight', 'visual.blocks.30.mlp.up_proj.base_layer.bias', 'visual.blocks.30.mlp.down_proj.base_layer.weight', 'visual.blocks.30.mlp.down_proj.base_layer.bias', 'visual.blocks.31.attn.qkv.base_layer.weight', 'visual.blocks.31.attn.qkv.base_layer.bias', 'visual.blocks.31.attn.proj.base_layer.weight', 'visual.blocks.31.attn.proj.base_layer.bias', 'visual.blocks.31.mlp.gate_proj.base_layer.weight', 'visual.blocks.31.mlp.gate_proj.base_layer.bias', 'visual.blocks.31.mlp.up_proj.base_layer.weight', 'visual.blocks.31.mlp.up_proj.base_layer.bias', 'visual.blocks.31.mlp.down_proj.base_layer.weight', 'visual.blocks.31.mlp.down_proj.base_layer.bias', 'visual.merger.mlp.0.base_layer.weight', 'visual.merger.mlp.0.base_layer.bias', 'visual.merger.mlp.2.base_layer.weight', 'visual.merger.mlp.2.base_layer.bias', 'model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.0.self_attn.q_proj.base_layer.bias', 'model.layers.0.self_attn.k_proj.base_layer.weight', 'model.layers.0.self_attn.k_proj.base_layer.bias', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.0.self_attn.v_proj.base_layer.bias', 'model.layers.0.self_attn.o_proj.base_layer.weight', 'model.layers.0.mlp.gate_proj.base_layer.weight', 'model.layers.0.mlp.up_proj.base_layer.weight', 'model.layers.0.mlp.down_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.base_layer.bias', 'model.layers.1.self_attn.k_proj.base_layer.weight', 'model.layers.1.self_attn.k_proj.base_layer.bias', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.v_proj.base_layer.bias', 'model.layers.1.self_attn.o_proj.base_layer.weight', 'model.layers.1.mlp.gate_proj.base_layer.weight', 'model.layers.1.mlp.up_proj.base_layer.weight', 'model.layers.1.mlp.down_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.base_layer.bias', 'model.layers.2.self_attn.k_proj.base_layer.weight', 'model.layers.2.self_attn.k_proj.base_layer.bias', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.base_layer.bias', 'model.layers.2.self_attn.o_proj.base_layer.weight', 'model.layers.2.mlp.gate_proj.base_layer.weight', 'model.layers.2.mlp.up_proj.base_layer.weight', 'model.layers.2.mlp.down_proj.base_layer.weight', 'model.layers.3.self_attn.q_proj.base_layer.weight', 'model.layers.3.self_attn.q_proj.base_layer.bias', 'model.layers.3.self_attn.k_proj.base_layer.weight', 'model.layers.3.self_attn.k_proj.base_layer.bias', 'model.layers.3.self_attn.v_proj.base_layer.weight', 'model.layers.3.self_attn.v_proj.base_layer.bias', 'model.layers.3.self_attn.o_proj.base_layer.weight', 'model.layers.3.mlp.gate_proj.base_layer.weight', 'model.layers.3.mlp.up_proj.base_layer.weight', 'model.layers.3.mlp.down_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.base_layer.bias', 'model.layers.4.self_attn.k_proj.base_layer.weight', 'model.layers.4.self_attn.k_proj.base_layer.bias', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.base_layer.bias', 'model.layers.4.self_attn.o_proj.base_layer.weight', 'model.layers.4.mlp.gate_proj.base_layer.weight', 'model.layers.4.mlp.up_proj.base_layer.weight', 'model.layers.4.mlp.down_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.base_layer.bias', 'model.layers.5.self_attn.k_proj.base_layer.weight', 'model.layers.5.self_attn.k_proj.base_layer.bias', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.v_proj.base_layer.bias', 'model.layers.5.self_attn.o_proj.base_layer.weight', 'model.layers.5.mlp.gate_proj.base_layer.weight', 'model.layers.5.mlp.up_proj.base_layer.weight', 'model.layers.5.mlp.down_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.base_layer.bias', 'model.layers.6.self_attn.k_proj.base_layer.weight', 'model.layers.6.self_attn.k_proj.base_layer.bias', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.base_layer.bias', 'model.layers.6.self_attn.o_proj.base_layer.weight', 'model.layers.6.mlp.gate_proj.base_layer.weight', 'model.layers.6.mlp.up_proj.base_layer.weight', 'model.layers.6.mlp.down_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.base_layer.bias', 'model.layers.7.self_attn.k_proj.base_layer.weight', 'model.layers.7.self_attn.k_proj.base_layer.bias', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.base_layer.bias', 'model.layers.7.self_attn.o_proj.base_layer.weight', 'model.layers.7.mlp.gate_proj.base_layer.weight', 'model.layers.7.mlp.up_proj.base_layer.weight', 'model.layers.7.mlp.down_proj.base_layer.weight', 'model.layers.8.self_attn.q_proj.base_layer.weight', 'model.layers.8.self_attn.q_proj.base_layer.bias', 'model.layers.8.self_attn.k_proj.base_layer.weight', 'model.layers.8.self_attn.k_proj.base_layer.bias', 'model.layers.8.self_attn.v_proj.base_layer.weight', 'model.layers.8.self_attn.v_proj.base_layer.bias', 'model.layers.8.self_attn.o_proj.base_layer.weight', 'model.layers.8.mlp.gate_proj.base_layer.weight', 'model.layers.8.mlp.up_proj.base_layer.weight', 'model.layers.8.mlp.down_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.base_layer.bias', 'model.layers.9.self_attn.k_proj.base_layer.weight', 'model.layers.9.self_attn.k_proj.base_layer.bias', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.base_layer.bias', 'model.layers.9.self_attn.o_proj.base_layer.weight', 'model.layers.9.mlp.gate_proj.base_layer.weight', 'model.layers.9.mlp.up_proj.base_layer.weight', 'model.layers.9.mlp.down_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.base_layer.bias', 'model.layers.10.self_attn.k_proj.base_layer.weight', 'model.layers.10.self_attn.k_proj.base_layer.bias', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.base_layer.bias', 'model.layers.10.self_attn.o_proj.base_layer.weight', 'model.layers.10.mlp.gate_proj.base_layer.weight', 'model.layers.10.mlp.up_proj.base_layer.weight', 'model.layers.10.mlp.down_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.base_layer.bias', 'model.layers.11.self_attn.k_proj.base_layer.weight', 'model.layers.11.self_attn.k_proj.base_layer.bias', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.base_layer.bias', 'model.layers.11.self_attn.o_proj.base_layer.weight', 'model.layers.11.mlp.gate_proj.base_layer.weight', 'model.layers.11.mlp.up_proj.base_layer.weight', 'model.layers.11.mlp.down_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.base_layer.bias', 'model.layers.12.self_attn.k_proj.base_layer.weight', 'model.layers.12.self_attn.k_proj.base_layer.bias', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.base_layer.bias', 'model.layers.12.self_attn.o_proj.base_layer.weight', 'model.layers.12.mlp.gate_proj.base_layer.weight', 'model.layers.12.mlp.up_proj.base_layer.weight', 'model.layers.12.mlp.down_proj.base_layer.weight', 'model.layers.13.self_attn.q_proj.base_layer.weight', 'model.layers.13.self_attn.q_proj.base_layer.bias', 'model.layers.13.self_attn.k_proj.base_layer.weight', 'model.layers.13.self_attn.k_proj.base_layer.bias', 'model.layers.13.self_attn.v_proj.base_layer.weight', 'model.layers.13.self_attn.v_proj.base_layer.bias', 'model.layers.13.self_attn.o_proj.base_layer.weight', 'model.layers.13.mlp.gate_proj.base_layer.weight', 'model.layers.13.mlp.up_proj.base_layer.weight', 'model.layers.13.mlp.down_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.base_layer.bias', 'model.layers.14.self_attn.k_proj.base_layer.weight', 'model.layers.14.self_attn.k_proj.base_layer.bias', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.base_layer.bias', 'model.layers.14.self_attn.o_proj.base_layer.weight', 'model.layers.14.mlp.gate_proj.base_layer.weight', 'model.layers.14.mlp.up_proj.base_layer.weight', 'model.layers.14.mlp.down_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.base_layer.bias', 'model.layers.15.self_attn.k_proj.base_layer.weight', 'model.layers.15.self_attn.k_proj.base_layer.bias', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.v_proj.base_layer.bias', 'model.layers.15.self_attn.o_proj.base_layer.weight', 'model.layers.15.mlp.gate_proj.base_layer.weight', 'model.layers.15.mlp.up_proj.base_layer.weight', 'model.layers.15.mlp.down_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.base_layer.bias', 'model.layers.16.self_attn.k_proj.base_layer.weight', 'model.layers.16.self_attn.k_proj.base_layer.bias', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.base_layer.bias', 'model.layers.16.self_attn.o_proj.base_layer.weight', 'model.layers.16.mlp.gate_proj.base_layer.weight', 'model.layers.16.mlp.up_proj.base_layer.weight', 'model.layers.16.mlp.down_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.base_layer.bias', 'model.layers.17.self_attn.k_proj.base_layer.weight', 'model.layers.17.self_attn.k_proj.base_layer.bias', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.base_layer.bias', 'model.layers.17.self_attn.o_proj.base_layer.weight', 'model.layers.17.mlp.gate_proj.base_layer.weight', 'model.layers.17.mlp.up_proj.base_layer.weight', 'model.layers.17.mlp.down_proj.base_layer.weight', 'model.layers.18.self_attn.q_proj.base_layer.weight', 'model.layers.18.self_attn.q_proj.base_layer.bias', 'model.layers.18.self_attn.k_proj.base_layer.weight', 'model.layers.18.self_attn.k_proj.base_layer.bias', 'model.layers.18.self_attn.v_proj.base_layer.weight', 'model.layers.18.self_attn.v_proj.base_layer.bias', 'model.layers.18.self_attn.o_proj.base_layer.weight', 'model.layers.18.mlp.gate_proj.base_layer.weight', 'model.layers.18.mlp.up_proj.base_layer.weight', 'model.layers.18.mlp.down_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.base_layer.bias', 'model.layers.19.self_attn.k_proj.base_layer.weight', 'model.layers.19.self_attn.k_proj.base_layer.bias', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.base_layer.bias', 'model.layers.19.self_attn.o_proj.base_layer.weight', 'model.layers.19.mlp.gate_proj.base_layer.weight', 'model.layers.19.mlp.up_proj.base_layer.weight', 'model.layers.19.mlp.down_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.base_layer.bias', 'model.layers.20.self_attn.k_proj.base_layer.weight', 'model.layers.20.self_attn.k_proj.base_layer.bias', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.base_layer.bias', 'model.layers.20.self_attn.o_proj.base_layer.weight', 'model.layers.20.mlp.gate_proj.base_layer.weight', 'model.layers.20.mlp.up_proj.base_layer.weight', 'model.layers.20.mlp.down_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.base_layer.bias', 'model.layers.21.self_attn.k_proj.base_layer.weight', 'model.layers.21.self_attn.k_proj.base_layer.bias', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.v_proj.base_layer.bias', 'model.layers.21.self_attn.o_proj.base_layer.weight', 'model.layers.21.mlp.gate_proj.base_layer.weight', 'model.layers.21.mlp.up_proj.base_layer.weight', 'model.layers.21.mlp.down_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.base_layer.bias', 'model.layers.22.self_attn.k_proj.base_layer.weight', 'model.layers.22.self_attn.k_proj.base_layer.bias', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.v_proj.base_layer.bias', 'model.layers.22.self_attn.o_proj.base_layer.weight', 'model.layers.22.mlp.gate_proj.base_layer.weight', 'model.layers.22.mlp.up_proj.base_layer.weight', 'model.layers.22.mlp.down_proj.base_layer.weight', 'model.layers.23.self_attn.q_proj.base_layer.weight', 'model.layers.23.self_attn.q_proj.base_layer.bias', 'model.layers.23.self_attn.k_proj.base_layer.weight', 'model.layers.23.self_attn.k_proj.base_layer.bias', 'model.layers.23.self_attn.v_proj.base_layer.weight', 'model.layers.23.self_attn.v_proj.base_layer.bias', 'model.layers.23.self_attn.o_proj.base_layer.weight', 'model.layers.23.mlp.gate_proj.base_layer.weight', 'model.layers.23.mlp.up_proj.base_layer.weight', 'model.layers.23.mlp.down_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.base_layer.bias', 'model.layers.24.self_attn.k_proj.base_layer.weight', 'model.layers.24.self_attn.k_proj.base_layer.bias', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.v_proj.base_layer.bias', 'model.layers.24.self_attn.o_proj.base_layer.weight', 'model.layers.24.mlp.gate_proj.base_layer.weight', 'model.layers.24.mlp.up_proj.base_layer.weight', 'model.layers.24.mlp.down_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.base_layer.bias', 'model.layers.25.self_attn.k_proj.base_layer.weight', 'model.layers.25.self_attn.k_proj.base_layer.bias', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.base_layer.bias', 'model.layers.25.self_attn.o_proj.base_layer.weight', 'model.layers.25.mlp.gate_proj.base_layer.weight', 'model.layers.25.mlp.up_proj.base_layer.weight', 'model.layers.25.mlp.down_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.base_layer.bias', 'model.layers.26.self_attn.k_proj.base_layer.weight', 'model.layers.26.self_attn.k_proj.base_layer.bias', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.base_layer.bias', 'model.layers.26.self_attn.o_proj.base_layer.weight', 'model.layers.26.mlp.gate_proj.base_layer.weight', 'model.layers.26.mlp.up_proj.base_layer.weight', 'model.layers.26.mlp.down_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.base_layer.bias', 'model.layers.27.self_attn.k_proj.base_layer.weight', 'model.layers.27.self_attn.k_proj.base_layer.bias', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.27.self_attn.v_proj.base_layer.bias', 'model.layers.27.self_attn.o_proj.base_layer.weight', 'model.layers.27.mlp.gate_proj.base_layer.weight', 'model.layers.27.mlp.up_proj.base_layer.weight', 'model.layers.27.mlp.down_proj.base_layer.weight', 'model.layers.28.self_attn.q_proj.base_layer.weight', 'model.layers.28.self_attn.q_proj.base_layer.bias', 'model.layers.28.self_attn.k_proj.base_layer.weight', 'model.layers.28.self_attn.k_proj.base_layer.bias', 'model.layers.28.self_attn.v_proj.base_layer.weight', 'model.layers.28.self_attn.v_proj.base_layer.bias', 'model.layers.28.self_attn.o_proj.base_layer.weight', 'model.layers.28.mlp.gate_proj.base_layer.weight', 'model.layers.28.mlp.up_proj.base_layer.weight', 'model.layers.28.mlp.down_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.base_layer.bias', 'model.layers.29.self_attn.k_proj.base_layer.weight', 'model.layers.29.self_attn.k_proj.base_layer.bias', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.base_layer.bias', 'model.layers.29.self_attn.o_proj.base_layer.weight', 'model.layers.29.mlp.gate_proj.base_layer.weight', 'model.layers.29.mlp.up_proj.base_layer.weight', 'model.layers.29.mlp.down_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.base_layer.bias', 'model.layers.30.self_attn.k_proj.base_layer.weight', 'model.layers.30.self_attn.k_proj.base_layer.bias', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.base_layer.bias', 'model.layers.30.self_attn.o_proj.base_layer.weight', 'model.layers.30.mlp.gate_proj.base_layer.weight', 'model.layers.30.mlp.up_proj.base_layer.weight', 'model.layers.30.mlp.down_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.base_layer.bias', 'model.layers.31.self_attn.k_proj.base_layer.weight', 'model.layers.31.self_attn.k_proj.base_layer.bias', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.v_proj.base_layer.bias', 'model.layers.31.self_attn.o_proj.base_layer.weight', 'model.layers.31.mlp.gate_proj.base_layer.weight', 'model.layers.31.mlp.up_proj.base_layer.weight', 'model.layers.31.mlp.down_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.base_layer.bias', 'model.layers.32.self_attn.k_proj.base_layer.weight', 'model.layers.32.self_attn.k_proj.base_layer.bias', 'model.layers.32.self_attn.v_proj.base_layer.weight', 'model.layers.32.self_attn.v_proj.base_layer.bias', 'model.layers.32.self_attn.o_proj.base_layer.weight', 'model.layers.32.mlp.gate_proj.base_layer.weight', 'model.layers.32.mlp.up_proj.base_layer.weight', 'model.layers.32.mlp.down_proj.base_layer.weight', 'model.layers.33.self_attn.q_proj.base_layer.weight', 'model.layers.33.self_attn.q_proj.base_layer.bias', 'model.layers.33.self_attn.k_proj.base_layer.weight', 'model.layers.33.self_attn.k_proj.base_layer.bias', 'model.layers.33.self_attn.v_proj.base_layer.weight', 'model.layers.33.self_attn.v_proj.base_layer.bias', 'model.layers.33.self_attn.o_proj.base_layer.weight', 'model.layers.33.mlp.gate_proj.base_layer.weight', 'model.layers.33.mlp.up_proj.base_layer.weight', 'model.layers.33.mlp.down_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.base_layer.bias', 'model.layers.34.self_attn.k_proj.base_layer.weight', 'model.layers.34.self_attn.k_proj.base_layer.bias', 'model.layers.34.self_attn.v_proj.base_layer.weight', 'model.layers.34.self_attn.v_proj.base_layer.bias', 'model.layers.34.self_attn.o_proj.base_layer.weight', 'model.layers.34.mlp.gate_proj.base_layer.weight', 'model.layers.34.mlp.up_proj.base_layer.weight', 'model.layers.34.mlp.down_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.base_layer.bias', 'model.layers.35.self_attn.k_proj.base_layer.weight', 'model.layers.35.self_attn.k_proj.base_layer.bias', 'model.layers.35.self_attn.v_proj.base_layer.weight', 'model.layers.35.self_attn.v_proj.base_layer.bias', 'model.layers.35.self_attn.o_proj.base_layer.weight', 'model.layers.35.mlp.gate_proj.base_layer.weight', 'model.layers.35.mlp.up_proj.base_layer.weight', 'model.layers.35.mlp.down_proj.base_layer.weight'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading additional Qwen2.5-VL weights...')\n",
    "non_lora_trainables = torch.load(os.path.join(model_path, 'non_lora_state_dict.bin'), map_location='cpu')\n",
    "non_lora_trainables = {(k[11:] if k.startswith('base_model.') else k): v for k, v in non_lora_trainables.items()}\n",
    "if any(k.startswith('model.model.') for k in non_lora_trainables):\n",
    "    non_lora_trainables = {(k[6:] if k.startswith('model.') else k): v for k, v in non_lora_trainables.items()}\n",
    "model.load_state_dict(non_lora_trainables, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0051720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f4163d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=123 environment variable detected; loading libbitsandbytes_cuda123.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA weights...\n"
     ]
    }
   ],
   "source": [
    "print('Loading LoRA weights...')\n",
    "model = PeftModel.from_pretrained(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b450e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA weights...\n"
     ]
    }
   ],
   "source": [
    "print('Merging LoRA weights...')\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88319 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Why is there a gap between the roof and wall?\n",
      "Answer: for ventilation\n",
      "Ground Truth: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions = {}\n",
    "# ground_truth = {}\n",
    "# for el in tqdm(data):\n",
    "#     # print(el)\n",
    "#     question_id = el[\"id\"]\n",
    "#     image = el[\"image\"]\n",
    "#     conversation = el[\"conversations\"]\n",
    "#     ground_truth[question_id] = conversation[-1][\"value\"]\n",
    "#     question = conversation[0][\"value\"]\n",
    "#     question = question.replace(\"<image>\\n\", \"\")\n",
    "#     file_path = image_path + \"/\" + image\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"image\", \"image\": f\"{file_path}\"},\n",
    "#                 {\"type\": \"text\", \"text\": f\"Provide a direct answer to the following question:\\n {question}\"},\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "#     # print(messages)\n",
    "#     # Preparation for inference\n",
    "#     text = processor.apply_chat_template(\n",
    "#         messages, tokenize=False, add_generation_prompt=True\n",
    "#     )\n",
    "#     image_inputs, video_inputs = process_vision_info(messages)\n",
    "#     inputs = processor(\n",
    "#         text=[text],\n",
    "#         images=image_inputs,\n",
    "#         videos=video_inputs,\n",
    "#         padding=True,\n",
    "#         return_tensors=\"pt\",\n",
    "#     )\n",
    "#     inputs = inputs.to(\"cuda\")\n",
    "\n",
    "#     # Inference: Generation of the output\n",
    "#     generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "#     generated_ids_trimmed = [\n",
    "#         out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "#     ]\n",
    "#     output_text = processor.batch_decode(\n",
    "#         generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#     )[0]\n",
    "#     print(f\"Question: {question}\")\n",
    "#     print(f\"Answer: {output_text}\")\n",
    "#     print(f\"Ground Truth: {ground_truth[question_id]}\")\n",
    "#     predictions[question_id] = output_text[0]\n",
    "#     # print(\"-----------------------------------------------------\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefbcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 128  # Adjust based on your GPU memory\n",
    "# tokenizer.padding_side  = 'left'\n",
    "processor.tokenizer.padding_side = \"left\"\n",
    "\n",
    "predictions = {}\n",
    "ground_truth = {}\n",
    "questions = {}\n",
    "\n",
    "# Process data in batches\n",
    "for i in tqdm(range(484, len(data), BATCH_SIZE)):\n",
    "    batch_data = data[i:i+BATCH_SIZE]\n",
    "    \n",
    "    batch_messages = []\n",
    "    batch_ids = []\n",
    "    \n",
    "    # Prepare batch inputs\n",
    "    for el in batch_data:\n",
    "        question_id = el[\"id\"]\n",
    "        image = el[\"image\"]\n",
    "        conversation = el[\"conversations\"]\n",
    "        \n",
    "        # Store ground truth\n",
    "        ground_truth[question_id] = conversation[-1][\"value\"]\n",
    "        \n",
    "        # Prepare question\n",
    "        question = conversation[0][\"value\"]\n",
    "        question = question.replace(\"<image>\\n\", \"\")\n",
    "        questions[question_id]=question\n",
    "        file_path = image_path + \"/\" + image\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": f\"{file_path}\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"Provide a direct answer to the following question:\\n {question}\"},\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        batch_messages.append(messages)\n",
    "        batch_ids.append(question_id)\n",
    "    \n",
    "    # Process batch\n",
    "    batch_texts = [\n",
    "        processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        ) for messages in batch_messages\n",
    "    ]\n",
    "    \n",
    "    # Process all images and videos in the batch\n",
    "    # batch_image_inputs = []\n",
    "    # batch_video_inputs = []\n",
    "    \n",
    "    # for messages in batch_messages:\n",
    "    #     image_inputs, video_inputs = process_vision_info(messages)\n",
    "    #     batch_image_inputs.append(image_inputs[0] if image_inputs else None)\n",
    "    #     batch_video_inputs.extend(video_inputs)\n",
    "    batch_image_inputs, batch_video_inputs = process_vision_info(batch_messages)\n",
    "    \n",
    "    # Handle inputs with processor\n",
    "    inputs = processor(\n",
    "        text=batch_texts,\n",
    "        images=batch_image_inputs, # if batch_image_inputs else None,\n",
    "        videos=batch_video_inputs, # if batch_video_inputs else None,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Batch inference\n",
    "    with torch.no_grad():  # Add this to save memory\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "    \n",
    "    # Process generated outputs\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    output_texts = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    \n",
    "    # Store predictions\n",
    "    for idx, question_id in enumerate(batch_ids):\n",
    "        if idx < len(output_texts):\n",
    "            # Make sure we're getting the first element if output_texts[idx] is a list\n",
    "            if isinstance(output_texts[idx], list):\n",
    "                predictions[question_id] = output_texts[idx][0]\n",
    "            else:\n",
    "                predictions[question_id] = output_texts[idx]\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fb092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
